# Project Structure

Last updated: October 4, 2025

## Directory Layout

```
market-signal/
â”‚
â”œâ”€â”€ ğŸ“ src/                           # Main source code
â”‚   â”œâ”€â”€ __init__.py                  # Package initialization
â”‚   â”œâ”€â”€ model.py                     # Pydantic data models for tweets
â”‚   â””â”€â”€ ğŸ“ scrapers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ playwright_scrapper.py   # âœ… WORKING scraper (recommended)
â”‚
â”œâ”€â”€ ğŸ“ archive/                       # Archived/non-working code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ğŸ“ scrapers/
â”‚       â”œâ”€â”€ README.md                # Explains why these don't work
â”‚       â”œâ”€â”€ snscrape_scraper.py     # âŒ Python 3.13 incompatible
â”‚       â”œâ”€â”€ twscrape_scraper.py     # âš ï¸ Returns 0 tweets
â”‚       â””â”€â”€ nitter_scraper.py       # âš ï¸ Unreliable
â”‚
â”œâ”€â”€ ğŸ“ docs/                          # Documentation
â”‚   â”œâ”€â”€ SCRAPER_COMPARISON.md        # Comparison of all scrapers
â”‚   â””â”€â”€ SCRAPER_IMPROVEMENTS.md      # Development notes
â”‚
â”œâ”€â”€ ğŸ“ debug/                         # Debug screenshots (auto-cleaned each run)
â”‚   â”œâ”€â”€ .gitkeep                     # Keeps folder in git
â”‚   â””â”€â”€ README.md                    # Debug folder documentation
â”‚
â”œâ”€â”€ ğŸ“ tests/                         # Unit tests (to be added)
â”‚
â”œâ”€â”€ ğŸ“„ run_scraper.py                # Main entry point â­
â”œâ”€â”€ ğŸ“„ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“„ README.md                     # Main documentation
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md          # This file
â”œâ”€â”€ ğŸ“„ .gitignore                    # Git ignore patterns
â”‚
â”œâ”€â”€ ğŸ“Š raw_tweets.json               # Output: collected tweets
â”œâ”€â”€ ğŸ“Š collection_stats.json         # Output: collection statistics
â”‚
â””â”€â”€ ğŸ“ venv/                          # Virtual environment (not in git)
```

## File Descriptions

### Source Code (`src/`)

| File | Purpose | Status |
|------|---------|--------|
| `model.py` | Pydantic Tweet model with validation | âœ… Working |
| `scrapers/playwright_scrapper.py` | Browser-based Twitter scraper | âœ… Working |

### Archive (`archive/`)

| File | Purpose | Status | Issue |
|------|---------|--------|-------|
| `scrapers/snscrape_scraper.py` | snscrape-based scraper | âŒ Broken | Python 3.13 incompatible |
| `scrapers/twscrape_scraper.py` | twscrape-based scraper | âš ï¸ Issues | Returns 0 tweets |
| `scrapers/nitter_scraper.py` | Nitter-based scraper | âš ï¸ Unreliable | Depends on public instances |

### Documentation (`docs/`)

| File | Purpose |
|------|---------|
| `SCRAPER_COMPARISON.md` | Detailed comparison of all scraper implementations |
| `SCRAPER_IMPROVEMENTS.md` | Development log and improvement notes |

### Root Files

| File | Purpose |
|------|---------|
| `run_scraper.py` | Main entry point - run this! |
| `requirements.txt` | Python package dependencies |
| `README.md` | Main project documentation |
| `.gitignore` | Files to exclude from git |

### Debug Folder (`debug/`)

| File | Content |
|------|---------|
| `.gitkeep` | Keeps folder tracked in git |
| `README.md` | Debug folder documentation |
| `*.png` | Screenshots from most recent run (auto-cleaned) |

### Output Files (Generated)

| File | Content |
|------|---------|
| `raw_tweets.json` | Collected tweets in JSON format |
| `collection_stats.json` | Statistics per hashtag |

## Usage

### Running the Scraper

```bash
# Recommended method
python run_scraper.py

# Direct method
python src/scrapers/playwright_scrapper.py
```

### Project Setup

```bash
# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
playwright install chromium
```

## Design Principles

1. **Separation of Concerns**
   - `src/` for working code
   - `archive/` for non-working/experimental code
   - `docs/` for documentation
   - `tests/` for future tests

2. **Modern Python Structure**
   - Package-based structure with `__init__.py`
   - Clean separation between modules
   - Single entry point (`run_scraper.py`)

3. **Documentation First**
   - Clear README
   - Inline documentation
   - Archived code with explanations

4. **Git-Friendly**
   - Proper `.gitignore`
   - No credentials in code
   - Clean commit history

## Future Enhancements

- [ ] Move credentials to environment variables
- [ ] Add unit tests in `tests/`
- [ ] Create `config.yml` for configuration
- [ ] Add data analysis notebooks
- [ ] Implement CI/CD pipeline
- [ ] Package for PyPI

## Migration Notes

### From Old Structure
```
OLD:                              NEW:
playwright_scrapper.py      â†’     src/scrapers/playwright_scrapper.py
model.py                    â†’     src/model.py
snscrape_scraper.py        â†’     archive/scrapers/snscrape_scraper.py
twscrape_scraper.py        â†’     archive/scrapers/twscrape_scraper.py
nitter_scraper.py          â†’     archive/scrapers/nitter_scraper.py
SCRAPER_COMPARISON.md      â†’     docs/SCRAPER_COMPARISON.md
SCRAPER_IMPROVEMENTS.md    â†’     docs/SCRAPER_IMPROVEMENTS.md
```

### Import Changes

If you have other Python files importing these modules:

```python
# OLD
from playwright_scrapper import TwitterScraper
from model import Tweet

# NEW
from src.scrapers.playwright_scrapper import TwitterScraper
from src.model import Tweet

# OR (if running from project root with run_scraper.py)
from scrapers.playwright_scrapper import TwitterScraper
from model import Tweet
```

