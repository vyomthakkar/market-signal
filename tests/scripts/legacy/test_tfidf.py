#!/usr/bin/env python3
"""
Test script for TF-IDF analysis
"""

import sys
from pathlib import Path
import logging

# Add src to path
src_path = Path(__file__).parent / "src"
sys.path.insert(0, str(src_path))

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

from analysis.features import TFIDFAnalyzer
import pandas as pd

print("\n" + "="*100)
print("ðŸ” TF-IDF ANALYSIS TEST")
print("="*100)

# Load tweets
df = pd.read_parquet('tweets_english.parquet')
tweets = df['cleaned_content'].tolist()

print(f"\nðŸ“Š Dataset: {len(tweets)} tweets")

# Initialize and fit TF-IDF
analyzer = TFIDFAnalyzer(max_features=500, ngram_range=(1, 2), min_df=1, top_n_terms=10)
analyzer.fit(tweets)

print(f"\nâœ… TF-IDF fitted with {len(analyzer.feature_names)} vocabulary terms")

# Test on a few sample tweets
print("\n" + "="*100)
print("ðŸ“‹ SAMPLE TWEET ANALYSIS")
print("="*100)

for i in range(min(3, len(tweets))):
    tweet = tweets[i]
    result = analyzer.transform(tweet)
    
    print(f"\n--- Tweet #{i+1} ---")
    print(f"Content: {tweet[:100]}...")
    print(f"\nðŸ” Top Terms:")
    for term, score in zip(result['top_tfidf_terms'], result['top_tfidf_scores']):
        print(f"  â€¢ {term}: {score:.3f}")
    print(f"\nðŸ“Š Finance term density: {result['finance_term_density']:.1%}")

# Get trending terms across all tweets
print("\n" + "="*100)
print("ðŸ”¥ TRENDING TERMS (Across All Tweets)")
print("="*100)

trending = analyzer.get_trending_terms(tweets, n=15)
for i, (term, score) in enumerate(trending, 1):
    print(f"{i:2d}. {term:20s} (score: {score:.4f})")

# Document similarity test
print("\n" + "="*100)
print("ðŸ”— DOCUMENT SIMILARITY TEST")
print("="*100)

if len(tweets) >= 2:
    sim = analyzer.get_document_similarity(tweets[0], tweets[1])
    print(f"\nSimilarity between Tweet #1 and Tweet #2: {sim:.3f}")
    
    print(f"\nTweet #1: {tweets[0][:80]}...")
    print(f"Tweet #2: {tweets[1][:80]}...")

print("\n" + "="*100)
print("âœ… TF-IDF test complete!")
print("="*100)

print("\nðŸ’¡ Key Insights:")
print("  â€¢ Each tweet gets top N most important terms")
print("  â€¢ Trending terms show what the market is talking about")
print("  â€¢ Finance term density shows how finance-focused a tweet is")
print("  â€¢ Can calculate similarity between any two tweets")
