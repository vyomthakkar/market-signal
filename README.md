# Market Signal Twitter Scraper ğŸ“Š

A robust Twitter/X scraper for collecting market-related tweets from Indian stock market discussions.

## ğŸ¯ Purpose

Scrape tweets about Indian stock market hashtags (#nifty50, #sensex, #intraday, #banknifty) for sentiment analysis and market signal detection.

## ğŸ“ Project Structure

```
market-signal/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model.py                  # Pydantic data models
â”‚   â””â”€â”€ scrapers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ playwright_scrapper.py  # Working scraper (recommended)
â”œâ”€â”€ archive/                      # Non-working/experimental code
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ README.md            # Why these don't work
â”‚   â”‚   â”œâ”€â”€ snscrape_scraper.py  # âŒ Python 3.13 incompatible
â”‚   â”‚   â”œâ”€â”€ twscrape_scraper.py  # âš ï¸ Returns 0 tweets
â”‚   â”‚   â””â”€â”€ nitter_scraper.py    # âš ï¸ Unreliable
â”œâ”€â”€ tests/                        # Tests (to be added)
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ run_scraper.py               # Main entry point
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ SCRAPER_COMPARISON.md        # Detailed scraper comparison
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone or download the repository
cd market-signal

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium
```

### 2. Configure Credentials

Edit `src/scrapers/playwright_scrapper.py` lines 403-405:

```python
TWITTER_USERNAME = "your_username"
TWITTER_PASSWORD = "your_password"
TWITTER_EMAIL = "your_email"  # If Twitter asks for verification
```

### 3. Run the Scraper

```bash
# Option 1: Use the main entry point
python run_scraper.py

# Option 2: Run directly
python src/scrapers/playwright_scrapper.py
```

## ğŸ“Š Output

The scraper produces two JSON files:

### `raw_tweets.json`
```json
[
  {
    "tweet_id": "1234567890",
    "username": "trader123",
    "timestamp": "2025-10-04T10:30:00",
    "content": "Tweet text here #nifty50",
    "replies": 5,
    "retweets": 12,
    "likes": 45,
    "views": 1200,
    "hashtags": ["nifty50"],
    "mentions": ["username"]
  }
]
```

### `collection_stats.json`
```json
{
  "nifty50": {
    "collected": 50,
    "target": 50,
    "percentage": 100.0
  },
  "sensex": {
    "collected": 48,
    "target": 50,
    "percentage": 96.0
  }
}
```

## âš™ï¸ Configuration

Edit `src/scrapers/playwright_scrapper.py` to customize:

```python
# Target hashtags
hashtags = ['nifty50', 'sensex', 'intraday', 'banknifty']

# Tweets per hashtag (50 for testing, 500+ for production)
tweets_per_tag = 50

# Browser visibility (False = visible, True = hidden)
headless = False
```

## ğŸ”§ Features

âœ… **Smart Scroll Detection**
- Stops after 3 consecutive scrolls with no new tweets
- Stops after 5 scrolls with unchanged page height

âœ… **Deduplication**
- Removes duplicate tweets across hashtags
- Based on unique tweet IDs

âœ… **Rate Limiting**
- Random delays between searches (5-10 seconds)
- Human-like scrolling behavior

âœ… **Statistics**
- Per-hashtag collection statistics
- Success rate tracking
- Duplicate detection

âœ… **Error Handling**
- Handles verification challenges
- Graceful degradation
- Detailed logging

## ğŸ“š Documentation

- **`SCRAPER_COMPARISON.md`** - Comparison of all scraper approaches
- **`archive/scrapers/README.md`** - Why alternative scrapers don't work
- **`SCRAPER_IMPROVEMENTS.md`** - Implementation improvements log

## ğŸ§ª Data Model

See `src/model.py` for the Pydantic Tweet model with validation.

## ğŸ› Troubleshooting

### Login Issues
- Check credentials in the script
- Provide email if Twitter asks for verification
- Check for CAPTCHA (run with `headless=False` to see browser)

### No Tweets Collected
- Hashtag might have limited recent content
- Rate limiting - wait 15 minutes and retry
- Check Twitter account isn't suspended

### Slow Performance
- Increase `headless` to True for faster execution
- Reduce `tweets_per_tag` for testing
- Check internet connection

## ğŸ“ License

This is a personal project for educational purposes. Respect Twitter's Terms of Service and rate limits.

## ğŸ¤ Contributing

This is a personal project, but suggestions are welcome!

## ğŸ“§ Support

For issues, check:
1. `SCRAPER_COMPARISON.md` for scraper options
2. `archive/scrapers/README.md` for known issues
3. GitHub issues (if repository is public)

---

**Note:** Only the Playwright scraper (`src/scrapers/playwright_scrapper.py`) is currently working. Other scrapers in `archive/` are kept for reference but are not functional.
